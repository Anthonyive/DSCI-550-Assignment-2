{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "electrical-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-queen",
   "metadata": {},
   "source": [
    "## I. convert emails text (both training and testing) into appropriate jsonl file format "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-defense",
   "metadata": {},
   "source": [
    "### 6088 entries in training set ( 2000+ machine generated, the rest are human-written)\n",
    "#### 4000+ are from email corpus, 2000+ are from gtp-2 generated and the ENRON Email Dataset \n",
    "###### kaggle datasets download -d nitishabharathi/email-spam-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dried-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/Users/jessicademacbook/DSCI-550-Assignment-2/data/Grover_input_output/8_GPT-2_Generated_Text_for_Grover/'\n",
    "folders = [f for f in os.listdir(PATH) if not f.startswith('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "romance-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all machine txt in each folders, label all machine generated content\n",
    "lis=[]\n",
    "for folder in folders:   \n",
    "    for i in os.listdir(f'{PATH}{folder}'):  \n",
    "        f=open(f'{PATH}{folder}/{i}','r')\n",
    "        text=f.read()\n",
    "        text_dic={\"article\":text,\"label\":\"machine\",\"split\":\"train\"}\n",
    "        lis.append(text_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "auburn-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all human json in email corpus, label all content as human\n",
    "path='/Users/jessicademacbook/DSCI-550-Assignment-1/data/separated by email/'\n",
    "for i in os.listdir(path):\n",
    "    if i.endswith('.json'):\n",
    "        f=open(f'{path}{i}','r')\n",
    "        text=json.load(f)\n",
    "        try:\n",
    "            content=text[\"X-TIKA:content\"]\n",
    "            if pd.isna(content):\n",
    "                pass\n",
    "            else:\n",
    "                content_dic={\"article\":content,\"label\":\"human\",\"split\":\"train\"}\n",
    "                lis.append(content_dic)\n",
    "        except KeyError:\n",
    "            pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "horizontal-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/jessicademacbook/DSCI-550-Assignment-2/data/Grover_input_output/fake_emails.csv', \"r\") as f:\n",
    "    result=pd.read_csv(f)\n",
    "    spam=result['Label']==1\n",
    "    for i in result[spam]['Body']:\n",
    "        if pd.isna(i):\n",
    "            pass\n",
    "        else:\n",
    "            dic={\"article\":i,\"label\":\"machine\",\"split\":\"train\"}\n",
    "            lis.append(dic)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "invalid-possibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set has  6087 emails in total.\n"
     ]
    }
   ],
   "source": [
    "print('The training set has ', len(lis),'emails in total.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "intended-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to a jsonl file with all human and machine generated email content\n",
    "with open('/Users/jessicademacbook/DSCI-550-Assignment-2/data/Grover_input_output/input_emails.jsonl','w') as outfile:\n",
    "    for entry in lis:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "normal-introduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are all content are NA-free? True\n"
     ]
    }
   ],
   "source": [
    "#check the written jsonl file has correct labels\n",
    "with open('/Users/jessicademacbook/DSCI-550-Assignment-2/data/Grover_input_output/input_emails.jsonl', \"r\") as f:\n",
    "    test=[]\n",
    "    for l in f:\n",
    "        item = json.loads(l)\n",
    "        if pd.isna(item['article']):\n",
    "            pass\n",
    "        else:\n",
    "            test.append(item['article'])\n",
    "print('Are all content are NA-free?', all(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-participation",
   "metadata": {},
   "source": [
    "### Collect 800 email text, labeled as test, write to jsonl file for discrimination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eleven-astronomy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file for discrimination has 800 emails in it.\n"
     ]
    }
   ],
   "source": [
    "#get generated text for grover test\n",
    "new_path = '/Users/jessicademacbook/DSCI-550-Assignment-2/data/additional-features-v2/new/4_GPT-2_Generated_Text/'\n",
    "folders = [f for f in os.listdir(new_path) if not f.startswith('.')]\n",
    "test_lis=[]\n",
    "for folder in folders:   \n",
    "    for i in os.listdir(f'{new_path}{folder}'):  \n",
    "        f=open(f'{new_path}{folder}/{i}','r')\n",
    "        text=f.read()\n",
    "        text_dic={\"article\":text,\"split\":\"test\",\"label\":\"machine\"}\n",
    "        test_lis.append(text_dic)\n",
    "print('The file for discrimination has', len(test_lis),'emails in it.')\n",
    "\n",
    "#write to jsonl file\n",
    "with open('/Users/jessicademacbook/DSCI-550-Assignment-2/data/Grover_input_output/test_input.jsonl','w') as f:\n",
    "    for entry in test_lis:\n",
    "        json.dump(entry, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-snake",
   "metadata": {},
   "source": [
    "## II. Grover Training-this part is done in Google Colab, and the corresponding notebook is called Grover_training in the same folder as this one "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-defense",
   "metadata": {},
   "source": [
    "see Grover_training.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-boring",
   "metadata": {},
   "source": [
    "## III. Interpreting Grover training result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "behavioral-demand",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-interference",
   "metadata": {},
   "source": [
    "#### The grover model returns a list of data pair showing the probability of the label being corrected. I labeled all the test input as machine, and the accuracy turns out to be 1, meaning that all 800 emails are identified as machine generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "palestinian-kansas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 20 pairs look like [[9.9662018e-01 3.3797552e-03]\n",
      " [9.9873632e-01 1.2636491e-03]\n",
      " [9.9940217e-01 5.9788820e-04]\n",
      " [9.9938750e-01 6.1247114e-04]\n",
      " [9.9944609e-01 5.5383943e-04]\n",
      " [9.9970198e-01 2.9801764e-04]\n",
      " [9.9898297e-01 1.0170500e-03]\n",
      " [9.9977785e-01 2.2213944e-04]\n",
      " [9.9598026e-01 4.0197591e-03]\n",
      " [9.9966323e-01 3.3679375e-04]\n",
      " [9.9684596e-01 3.1541178e-03]\n",
      " [9.9589598e-01 4.1040764e-03]\n",
      " [9.9823952e-01 1.7604964e-03]\n",
      " [9.9984765e-01 1.5229598e-04]\n",
      " [9.9863845e-01 1.3614852e-03]\n",
      " [9.9976915e-01 2.3089335e-04]\n",
      " [9.9954545e-01 4.5462951e-04]\n",
      " [9.9974865e-01 2.5135945e-04]\n",
      " [9.9943906e-01 5.6092546e-04]\n",
      " [9.9943274e-01 5.6727190e-04]]\n",
      "797 of 800 emails have probability of being machine generated higher than 0.95.\n",
      "All emails are identified as machine generated.\n"
     ]
    }
   ],
   "source": [
    "path='/Users/jessicademacbook/DSCI-550-Assignment-2/data/Grover_input_output/final_outputs_test-probs.npy'\n",
    "data_array = np.load(path)\n",
    "print('The first 20 pairs look like', data_array[0:20])\n",
    "a=0\n",
    "for i in data_array:\n",
    "    if i[0]>0.95:\n",
    "        a=a+1\n",
    "print(a,\"of 800 emails have probability of being machine generated higher than 0.95.\")\n",
    "print(\"All emails are identified as machine generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "terminal-tiffany",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 7 fields in line 49, saw 9\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-eaac3c53db37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/Users/jessicademacbook/DSCI-550-Assignment-2/data/additional-features-v2/new/assignment2.tsv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#f=open(path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtsv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2155\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 7 fields in line 49, saw 9\n"
     ]
    }
   ],
   "source": [
    "path='/Users/jessicademacbook/DSCI-550-Assignment-2/data/additional-features-v2/new/assignment2.tsv'\n",
    "#f=open(path)\n",
    "tsv=pd.read_csv(path,sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "human_or_machine=['machine']*800+[np.nan]*2400\n",
    "tsv['grover_result']=human_or_machine\n",
    "tsv.head(10)\n",
    "with open('/Users/jessicademacbook/DSCI-550-Assignment-2/data/additional-features-v2/new/assignment2.tsv', 'wt') as out_file:\n",
    "    tsv.to_csv(out_file, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
