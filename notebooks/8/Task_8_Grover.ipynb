{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "settled-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-trader",
   "metadata": {},
   "source": [
    "## I. convert emails text (both training and testing) into appropriate jsonl file format "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-services",
   "metadata": {},
   "source": [
    "### 6088 entries in training set ( 2000+ machine generated, the rest are human-written)\n",
    "#### 4000+ are from email corpus, 2000+ are from gtp-2 generated and the ENRON Email Dataset \n",
    "###### kaggle datasets download -d nitishabharathi/email-spam-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "graphic-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/Users/jessicademacbook/DSCI-550-Assignment-2/data/additional-features-v2/new/8_GPT-2_Generated_Text_for_Grover/'\n",
    "folders = [f for f in os.listdir(PATH) if not f.startswith('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "tropical-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all machine txt in each folders, label all machine generated content\n",
    "lis=[]\n",
    "for folder in folders:   \n",
    "    for i in os.listdir(f'{PATH}{folder}'):  \n",
    "        f=open(f'{PATH}{folder}/{i}','r')\n",
    "        text=f.read()\n",
    "        text_dic={\"text\":text,\"label\":\"machine\",\"split\":\"train\"}\n",
    "        lis.append(text_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "silent-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all human json in email corpus, label all content as human\n",
    "path='/Users/jessicademacbook/DSCI-550-Assignment-1/data/separated by email/'\n",
    "for i in os.listdir(path):\n",
    "    if i.endswith('.json'):\n",
    "        f=open(f'{path}{i}','r')\n",
    "        text=json.load(f)\n",
    "        try:\n",
    "            content=text[\"X-TIKA:content\"]\n",
    "            content_dic={\"text\":content,\"label\":\"human\",\"split\":\"train\"}\n",
    "            lis.append(content_dic)\n",
    "        except KeyError:\n",
    "            pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "handled-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/jessicademacbook/DSCI-550-Assignment-2/data/additional-features-v2/new/fake_emails.csv', \"r\") as f:\n",
    "    result=pd.read_csv(f)\n",
    "    spam=result['Label']==1\n",
    "    for i in result[spam]['Body']:\n",
    "        dic={\"text\":i,\"label\":\"machine\",\"split\":\"train\"}\n",
    "        lis.append(dic)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dated-serial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6088"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ethical-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to a jsonl file with all human and machine generated email content\n",
    "with open('/Users/jessicademacbook/DSCI-550-Assignment-2/data/input_emails.jsonl','w') as outfile:\n",
    "    for entry in lis:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "opened-disclaimer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#check the written jsonl file has correct labels\n",
    "with open('/Users/jessicademacbook/DSCI-550-Assignment-2/data/input_emails.jsonl', \"r\") as f:\n",
    "    test=[]\n",
    "    for l in f:\n",
    "        item = json.loads(l)\n",
    "        test.append(item['split'])\n",
    "print(all(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-destiny",
   "metadata": {},
   "source": [
    "### Collect 800 email text, labeled as test, write to jsonl file for discrimination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "smooth-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/jessicademacbook/DSCI-550-Assignment-2/data/test_file.jsonl','w') as f:\n",
    "    for entry in a_lis:\n",
    "        json.dump(entry, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "central-exemption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    }
   ],
   "source": [
    "#get generated text for grover test\n",
    "new_path = '/Users/jessicademacbook/DSCI-550-Assignment-2/data/additional-features-v2/new/4_GPT-2_Generated_Text/'\n",
    "folders = [f for f in os.listdir(new_path) if not f.startswith('.')]\n",
    "test_lis=[]\n",
    "for folder in folders:   \n",
    "    for i in os.listdir(f'{new_path}{folder}'):  \n",
    "        f=open(f'{new_path}{folder}/{i}','r')\n",
    "        text=f.read()\n",
    "        text_dic={\"text\":text,\"split\":\"test\",\"label\":\"human\"}\n",
    "        test_lis.append(text_dic)\n",
    "print(len(test_lis))\n",
    "\n",
    "#write to jsonl file\n",
    "with open('/Users/jessicademacbook/DSCI-550-Assignment-2/data/test_input.jsonl','w') as f:\n",
    "    for entry in test_lis:\n",
    "        json.dump(entry, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-bruce",
   "metadata": {},
   "source": [
    "## II. Interpret Grover output result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "critical-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "confirmed-pipeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9933362  0.00666374]\n",
      " [0.9933362  0.00666374]\n",
      " [0.9933362  0.00666374]\n",
      " [0.9933362  0.00666374]\n",
      " [0.9933362  0.00666374]\n",
      " [0.9933362  0.00666374]\n",
      " [0.9933362  0.00666374]\n",
      " [0.9933362  0.00666374]\n",
      " [0.9933362  0.00666374]\n",
      " [0.9933362  0.00666374]]\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "path='/Users/jessicademacbook/DSCI-550-Assignment-2/data/Grover_input_output/output_test-probs_5.npy'\n",
    "data_array = np.load(path)\n",
    "print(data_array[0:10])\n",
    "a=0\n",
    "for i in data_array:\n",
    "    if i[0]>0.9:\n",
    "        a=a+1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-session",
   "metadata": {},
   "source": [
    "#####  I am getting same result for every entries. I've tried using different combinations of training data (e.g. 4000 machine+200 human, 4000 human+3000 machine), but accuracy result is either 0 or 1. Output result probs are all the same. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
