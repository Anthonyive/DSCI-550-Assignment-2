{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cea64cd",
   "metadata": {},
   "source": [
    "# Huggingface GPT-2 text generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77023f29",
   "metadata": {},
   "source": [
    "## Reply 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da05c3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
    "import os, random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35f57229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6f25465bed449691491d4b68646e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3fc91015564de5a17483041fb3b80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e7f78d06cb4bd686fe16210dc42a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360756d35ddb4593bc21a6d0242072ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8571fbdfd2de44d389630c8b70af18c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH = \"../data/additional-features-v2/new/4_GPT-2_Generated_Text/\"\n",
    "PERSONA_PROMPTS_BOS = {\n",
    "    \"IT Newbie\": [\"You want my bank account, I'm having trouble turning the computer on. Can you help me?\", \"I don't know. \", \"I can't understand what you mean by that\",\"This is too hard for me.\",\"I can not access to my bank account so I would have to go to the bank to retrieve my information.\"],\n",
    "    \"Investigator\": [\"You wanted my SSN, here is my birthday, where are you located?\", \"I need to verify your identity\", \"Why would you need those information from me?\"],\n",
    "    \"Annoyed elderly\": [\"Stop sending me requests for my account so early!\", \"I'll let my son help me.\", \"I don't have my own computer, could you buy me one?\"],\n",
    "    \"Angry victim\":[\"Do you really think I would believe in this trash?\", \"Stop sending message to this email address or I'll call the cops!\"],\n",
    "    \"Single man\":[\"Hey,yes! I can definitely provide you my information. Do you wanna meet up somewhere? Maybe we can grab a cup of coffee and talk more about the details later.\"],\n",
    "    \"LAPD\": [\"Call me at 911.\",\"You have been located\"],\n",
    "    \"Psycho people\":[\"对不起，我不明白你在说什么。\", \"You are the lier!\", \"F**k you!\", \"I am not stupid. \",\"I am a genius!\",\"Stop lying! I'm going to use my IQ to arrest you!\", \"I know scammers better than anyone else.\", \"Nobody knows scammers better than me.\", \"You were a young baby when I was a huge scammer, boi :)\"], \n",
    "\t\"Hacker\": [\"Your computer has been hacked.\",\"I've located your ip address.\"], \n",
    "\t\"Dumb\": [\"My SNN is 123-456-7890.\", \"Thank you so much!\", \"How can I get the money?\", \"OMG I'm so lucky!\"], \n",
    "    \"Smart investigator\":[\"I will go to Western Union to write you the check tomorrow. Could you provide me with the receiver information? Thanks!\"]\n",
    "}\n",
    "PROMPT_PREFIX = ['Hello, ', \"Hi, \", \"Dear, \", \"To whom may concern, \",\"Hey,\", \"Yo\"]\n",
    "\n",
    "for AttackType in tqdm(os.listdir(PATH)):\n",
    "    if AttackType.startswith('.'):\n",
    "        continue\n",
    "    for email in tqdm(os.listdir(os.path.join(PATH, AttackType))):\n",
    "        if email.startswith('.'):\n",
    "            continue\n",
    "            \n",
    "#         print(AttackType, email)\n",
    "        email_file = open(os.path.join(PATH, AttackType, email))\n",
    "\n",
    "        # Padding text helps XLNet with short prompts - proposed by Aman Rusia in https://github.com/rusiaaman/XLNet-gen#methodology\n",
    "        PADDING_TEXT = email_file.read()\n",
    "        \n",
    "        persona_prompt = random.choice(list(PERSONA_PROMPTS_BOS.items()))\n",
    "        persona = persona_prompt[0]\n",
    "        prompt_prefix = random.choice(PROMPT_PREFIX)\n",
    "        prompt = prompt_prefix + random.choice(persona_prompt[1])\n",
    "        \n",
    "        \n",
    "        inputs = tokenizer.encode(PADDING_TEXT + prompt, add_special_tokens=False, return_tensors=\"tf\", max_length=256, truncation=True)\n",
    "        prompt_length = len(tokenizer.decode(inputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))\n",
    "        outputs = model.generate(inputs, max_length=512, do_sample=True, top_p=0.95, top_k=60)\n",
    "        generated = prompt + tokenizer.decode(outputs[0])[prompt_length:]\n",
    "        \n",
    "        email_file.close()\n",
    "        \n",
    "        with open(f'../data/additional-features-v2/new/10_Replies/replies#1/{AttackType}_{email[:-4]}_reply#1.txt', 'w') as outFile:\n",
    "            outFile.write(generated)\n",
    "#         break\n",
    "        \n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c7170e",
   "metadata": {},
   "source": [
    "## Reply 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b834492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e90ef15f7641e4ace0e163f100657f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/801 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH = \"../data/additional-features-v2/new/10_Replies/replies#1/\"\n",
    "PERSONA_PROMPTS_BOS = {\n",
    "    \"Scammer\": [\"We are good people. \", \"Please provide me your bank account number and the 3 digits on the back. \", \"You have a package in Fedex, please call us back! \", \"YOU ARE THE WINNER!\", \"I can give you $500 Target gift card.\"],\n",
    "    \"Bots\": [\"You account has been temporarily disabled, please contact us for activation.\", \"Urgency Alert, please reply within 3 days\",\"Here is the chance to win the big prize!\",\"I am not a robot. This is a real person writing here.\", \"This is Donald Trump, I am RICH. I can give you 100,000,000 dollars. \", \"You have an unpaid debt.\"],\n",
    "    \"Social Scammers\": [\"I am an old friend of your father's. \", \"Your grandfather has left you a heritage.\", \"Your father abandoned me and my mother 10 years ago.\"]\n",
    "}\n",
    "PROMPT_PREFIX = ['Hello, ', \"Hi, \", \"Dear, \", \"To whom may concern, \",\"Hey,\", \"Yo\"]\n",
    "\n",
    "for email in tqdm(os.listdir(os.path.join(PATH))):\n",
    "    if email.startswith('.'):\n",
    "        continue\n",
    "        \n",
    "    if os.path.exists(f'../data/additional-features-v2/new/10_Replies/replies#2/{email[:-5]}2.txt'):\n",
    "        continue\n",
    "\n",
    "    email_file = open(os.path.join(PATH, email))\n",
    "\n",
    "    # Padding text helps XLNet with short prompts - proposed by Aman Rusia in https://github.com/rusiaaman/XLNet-gen#methodology\n",
    "    PADDING_TEXT = email_file.read()\n",
    "\n",
    "    persona_prompt = random.choice(list(PERSONA_PROMPTS_BOS.items()))\n",
    "    persona = persona_prompt[0]\n",
    "    prompt_prefix = random.choice(PROMPT_PREFIX)\n",
    "    prompt = prompt_prefix + random.choice(persona_prompt[1])\n",
    "\n",
    "\n",
    "    inputs = tokenizer.encode(PADDING_TEXT + prompt, add_special_tokens=False, return_tensors=\"tf\", max_length=256, truncation=True)\n",
    "    prompt_length = len(tokenizer.decode(inputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))\n",
    "    outputs = model.generate(inputs, max_length=512, do_sample=True, top_p=0.95, top_k=60)\n",
    "    generated = prompt + tokenizer.decode(outputs[0])[prompt_length:]\n",
    "\n",
    "    email_file.close()\n",
    "\n",
    "    with open(f'../data/additional-features-v2/new/10_Replies/replies#2/{email[:-5]}2.txt', 'w') as outFile:\n",
    "        outFile.write(generated)\n",
    "#         break\n",
    "        \n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b0af6a",
   "metadata": {},
   "source": [
    "## Reply 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "999d6e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9339391107f542e59099646625f6b7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/801 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH = \"../data/additional-features-v2/new/10_Replies/replies#2/\"\n",
    "PERSONA_PROMPTS_BOS = {\n",
    "    \"IT Newbie\": [\"You want my bank account, I'm having trouble turning the computer on. Can you help me?\", \"I don't know. \", \"I can't understand what you mean by that\",\"This is too hard for me.\",\"I can not access to my bank account so I would have to go to the bank to retrieve my information.\"],\n",
    "    \"Investigator\": [\"You wanted my SSN, here is my birthday, where are you located?\", \"I need to verify your identity\", \"Why would you need those information from me?\"],\n",
    "    \"Annoyed elderly\": [\"Stop sending me requests for my account so early!\", \"I'll let my son help me.\", \"I don't have my own computer, could you buy me one?\"],\n",
    "    \"Angry victim\":[\"Do you really think I would believe in this trash?\", \"Stop sending message to this email address or I'll call the cops!\"],\n",
    "    \"Single man\":[\"Hey,yes! I can definitely provide you my information. Do you wanna meet up somewhere? Maybe we can grab a cup of coffee and talk more about the details later.\"],\n",
    "    \"LAPD\": [\"Call me at 911.\",\"You have been located\"],\n",
    "    \"Psycho people\":[\"You are the lier!\", \"F**k you!\", \"I am not stupid. \",\"I am a genius!\",\"Stop lying! I'm going to use my IQ to arrest you!\", \"I know scammers better than anyone else.\", \"Nobody knows scammers better than me.\", \"You were a young baby when I was a huge scammer, boi :)\"], \n",
    "\t\"Hacker\": [\"Your computer has been hacked.\",\"I've located your ip address.\"], \n",
    "\t\"Dumb\": [\"My SNN is 123-456-7890.\", \"Thank you so much!\", \"How can I get the money?\", \"OMG I'm so lucky!\"], \n",
    "    \"Smart investigator\":[\"I will go to Western Union to write you the check tomorrow. Could you provide me with the receiver information? Thanks!\"]\n",
    "}\n",
    "PROMPT_PREFIX = ['Hello, ', \"Hi, \", \"Dear, \", \"To whom may concern, \",\"Hey,\", \"Yo\"]\n",
    "\n",
    "for email in tqdm(os.listdir(os.path.join(PATH))):\n",
    "    if email.startswith('.'):\n",
    "        continue\n",
    "        \n",
    "    if os.path.exists(f'../data/additional-features-v2/new/10_Replies/replies#3/{email[:-5]}3.txt'):\n",
    "        continue\n",
    "\n",
    "    email_file = open(os.path.join(PATH, email))\n",
    "\n",
    "    # Padding text helps XLNet with short prompts - proposed by Aman Rusia in https://github.com/rusiaaman/XLNet-gen#methodology\n",
    "    PADDING_TEXT = email_file.read()\n",
    "\n",
    "    persona_prompt = random.choice(list(PERSONA_PROMPTS_BOS.items()))\n",
    "    persona = persona_prompt[0]\n",
    "    prompt_prefix = random.choice(PROMPT_PREFIX)\n",
    "    prompt = prompt_prefix + random.choice(persona_prompt[1])\n",
    "\n",
    "\n",
    "    inputs = tokenizer.encode(PADDING_TEXT + prompt, add_special_tokens=False, return_tensors=\"tf\", max_length=256, truncation=True)\n",
    "    prompt_length = len(tokenizer.decode(inputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))\n",
    "    outputs = model.generate(inputs, max_length=512, do_sample=True, top_p=0.95, top_k=60)\n",
    "    generated = prompt + tokenizer.decode(outputs[0])[prompt_length:]\n",
    "\n",
    "    email_file.close()\n",
    "\n",
    "    with open(f'../data/additional-features-v2/new/10_Replies/replies#3/{email[:-5]}3.txt', 'w') as outFile:\n",
    "        outFile.write(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ce3eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c806a54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSCI-550-Assignment-2",
   "language": "python",
   "name": "dsci-550-assignment-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
