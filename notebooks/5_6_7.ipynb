{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "average-consumption",
   "metadata": {},
   "source": [
    "### to run this notebook, you need: python 3.7, tensorflow 2.2.0, numpy 1.19.0 or earlier\n",
    "#### for the other libraries, the most recent versions are compatible with this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "federal-invalid",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# great example here: \n",
    "# https://idiotdeveloper.com/dcgan-implementing-deep-convolutional-generative-adversarial-network-in-tensorflow/\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "from matplotlib import pyplot\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "powerful-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "IMG_H = 64\n",
    "IMG_W = 64\n",
    "IMG_C = 3\n",
    "batch_size = 128\n",
    "latent_dim = 128\n",
    "num_epochs = 60\n",
    "# images_path = glob(\"data/*\")\n",
    "images_path = glob('../../input/reconnaissance/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "naked-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "floral-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.io.decode_jpeg(img)\n",
    "    img = tf.image.resize_with_crop_or_pad(img, IMG_H, IMG_W)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = (img - 127.5) / 127.5\n",
    "    # resize image\n",
    "    img = img[:, :, :3]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rental-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_dataset(images_path, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(images_path)\n",
    "    dataset = dataset.shuffle(buffer_size=10240)\n",
    "    dataset = dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ranking-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv_block(inputs, num_filters, kernel_size, strides, bn=True):\n",
    "    x = Conv2DTranspose(\n",
    "        filters=num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        kernel_initializer=w_init,\n",
    "        padding=\"same\",\n",
    "        strides=strides,\n",
    "        use_bias=False\n",
    "        )(inputs)\n",
    "\n",
    "    if bn:\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "organized-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters, kernel_size, padding=\"same\", strides=2, activation=True):\n",
    "    x = Conv2D(\n",
    "        filters=num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        kernel_initializer=w_init,\n",
    "        padding=padding,\n",
    "        strides=strides,\n",
    "    )(inputs)\n",
    "\n",
    "    if activation:\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fewer-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_dim):\n",
    "    f = [2**i for i in range(5)][::-1]\n",
    "    filters = 32\n",
    "    output_strides = 16\n",
    "    h_output = IMG_H // output_strides\n",
    "    w_output = IMG_W // output_strides\n",
    "\n",
    "    noise = Input(shape=(latent_dim,), name=\"generator_noise_input\")\n",
    "\n",
    "    x = Dense(f[0] * filters * h_output * w_output, use_bias=False)(noise)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Reshape((h_output, w_output, 16 * filters))(x)\n",
    "\n",
    "    for i in range(1, 5):\n",
    "        x = deconv_block(x,\n",
    "            num_filters=f[i] * filters,\n",
    "            kernel_size=5,\n",
    "            strides=2,\n",
    "            bn=True\n",
    "        )\n",
    "\n",
    "    x = conv_block(x,\n",
    "        num_filters=3,\n",
    "        kernel_size=5,\n",
    "        strides=1,\n",
    "        activation=False\n",
    "    )\n",
    "    fake_output = Activation(\"tanh\")(x)\n",
    "\n",
    "    return Model(noise, fake_output, name=\"generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "atomic-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    f = [2**i for i in range(4)]\n",
    "    image_input = Input(shape=(IMG_H, IMG_W, IMG_C))\n",
    "    x = image_input\n",
    "    filters = 64\n",
    "    output_strides = 16\n",
    "    h_output = IMG_H // output_strides\n",
    "    w_output = IMG_W // output_strides\n",
    "\n",
    "    for i in range(0, 4):\n",
    "        x = conv_block(x, num_filters=f[i] * filters, kernel_size=5, strides=2)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1)(x)\n",
    "\n",
    "    return Model(image_input, x, name=\"discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "living-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        for _ in range(2):\n",
    "            ## Train the discriminator\n",
    "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            generated_images = self.generator(random_latent_vectors)\n",
    "            generated_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "            with tf.GradientTape() as ftape:\n",
    "                predictions = self.discriminator(generated_images)\n",
    "                d1_loss = self.loss_fn(generated_labels, predictions)\n",
    "            grads = ftape.gradient(d1_loss, self.discriminator.trainable_weights)\n",
    "            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "\n",
    "            ## Train the discriminator\n",
    "            labels = tf.ones((batch_size, 1))\n",
    "\n",
    "            with tf.GradientTape() as rtape:\n",
    "                predictions = self.discriminator(real_images)\n",
    "                d2_loss = self.loss_fn(labels, predictions)\n",
    "            grads = rtape.gradient(d2_loss, self.discriminator.trainable_weights)\n",
    "            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "\n",
    "        ## Train the generator\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        misleading_labels = tf.ones((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as gtape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = gtape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        return {\"d1_loss\": d1_loss, \"d2_loss\": d2_loss, \"g_loss\": g_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "jewish-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(examples, epoch, n):\n",
    "    examples = (examples + 1) / 2.0\n",
    "    for i in range(n * n):\n",
    "        pyplot.subplot(n, n, i+1)\n",
    "        pyplot.axis(\"off\")\n",
    "        pyplot.imshow(examples[i])\n",
    "    filename = f\"../models/samples/generated_plot_epoch-{epoch+1}.png\"\n",
    "    pyplot.savefig(filename)\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "understanding-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_image(model, noise_dim=latent_dim):\n",
    "    test_input = tf.random.normal([1, noise_dim])\n",
    "    # Notice `training` is set to False.\n",
    "    # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training=False)\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    plt.imshow((predictions[0, :, :, :] * 127.5 + 127.5) / 255.)\n",
    "    plt.axis('off') \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "korean-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_show_images(generator, noise_dim=latent_dim, rows=4, cols=4):\n",
    "    predictions = generator(tf.random.normal([16, noise_dim]))\n",
    "    print(predictions.shape)\n",
    "    fig = plt.figure(figsize=(9,9))\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        plt.imshow((predictions[i, :, :, :] * 127.5 + 127.5) / 255.)\n",
    "        plt.axis('off') \n",
    "        \n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "valid-marijuana",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 4,314,753\n",
      "Trainable params: 4,314,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_noise_input (Input [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8192)              1048576   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8192)              32768     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 8, 8, 256)         3276800   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 16, 16, 128)       819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 32, 32, 64)        204800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 64, 64, 32)        51200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 3)         2403      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 64, 64, 3)         0         \n",
      "=================================================================\n",
      "Total params: 5,437,667\n",
      "Trainable params: 5,420,323\n",
      "Non-trainable params: 17,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "d_model = build_discriminator()\n",
    "g_model = build_generator(latent_dim)\n",
    "\n",
    "if os.path.exists('../models/saved_model/d_model.h5') and os.path.exists('../models/saved_model/g_model.h5'):\n",
    "    d_model.load_weights(\"../models/saved_model/d_model.h5\")\n",
    "    g_model.load_weights(\"../models/saved_model/g_model.h5\")\n",
    "else:\n",
    "    gan = GAN(d_model, g_model, latent_dim)\n",
    "    bce_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=0.1)\n",
    "    d_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    g_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    gan.compile(d_optimizer, g_optimizer, bce_loss_fn)\n",
    "    images_dataset = tf_dataset(images_path, batch_size)\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        gan.fit(images_dataset, epochs=1)\n",
    "        g_model.save(\"../models/saved_model/g_model.h5\")\n",
    "        d_model.save(\"../models/saved_model/d_model.h5\")\n",
    "\n",
    "        n_samples = 25\n",
    "        noise = np.random.normal(size=(n_samples, latent_dim))\n",
    "        examples = g_model.predict(noise)\n",
    "        save_plot(examples, epoch, int(np.sqrt(n_samples)))\n",
    "\n",
    "d_model.summary()\n",
    "g_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-effect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bearing-narrow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_test_image(g_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "communist-spelling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 64, 64, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_and_show_images(g_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-reporter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-marketplace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSCI-550-Assignment-2",
   "language": "python",
   "name": "dsci-550-assignment-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
